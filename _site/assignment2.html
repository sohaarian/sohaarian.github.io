<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Assignment 2 – Prompt Exercise – sohaarian.github.io</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">sohaarian.github.io</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./project.html"> 
<span class="menu-text">Project</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-weekly-reflections" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Weekly Reflections</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-weekly-reflections">    
        <li>
    <a class="dropdown-item" href="./week1-reflection.html">
 <span class="dropdown-text">All Weekly Reflections</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-assignments" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Assignments</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-assignments">    
        <li>
    <a class="dropdown-item" href="./assignment1.html">
 <span class="dropdown-text">Soha Arian Assignment 1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./assignment2.html">
 <span class="dropdown-text">Soha Arian Assignment 2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./assignment3.html">
 <span class="dropdown-text">Soha Arian Assignment 3</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./lab1.html">
 <span class="dropdown-text">Soha Arian Lab 01</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./lab2.html">
 <span class="dropdown-text">Soha Arian Lab 02</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#objective" id="toc-objective" class="nav-link active" data-scroll-target="#objective">Objective</a></li>
  <li><a href="#design-prompt" id="toc-design-prompt" class="nav-link" data-scroll-target="#design-prompt"><strong>Design Prompt</strong></a></li>
  <li><a href="#model-response-analysis" id="toc-model-response-analysis" class="nav-link" data-scroll-target="#model-response-analysis"><strong>Model Response Analysis</strong></a></li>
  <li><a href="#analyze-model-responses" id="toc-analyze-model-responses" class="nav-link" data-scroll-target="#analyze-model-responses"><strong>Analyze Model Responses</strong></a></li>
  <li><a href="#refined-prompts" id="toc-refined-prompts" class="nav-link" data-scroll-target="#refined-prompts"><strong>Refined Prompts</strong></a></li>
  <li><a href="#final-prompt" id="toc-final-prompt" class="nav-link" data-scroll-target="#final-prompt"><strong>Final Prompt</strong></a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><strong>Reflection</strong></a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Assignment 2 – Prompt Exercise</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="objective" class="level2">
<h2 class="anchored" data-anchor-id="objective">Objective</h2>
<p>This assignment shows how different AI models respond to the same research task. The goal is to design prompts, evaluate model outputs, refine instructions, and understand how prompt structure impacts response quality.</p>
</section>
<section id="design-prompt" class="level2">
<h2 class="anchored" data-anchor-id="design-prompt"><strong>Design Prompt</strong></h2>
<p>For the first test, I submitted the following prompt to multiple AI models:</p>
<p>Write a 1,500 word literature review that reads like an analytical discussion rather than a textbook summary. Start by explaining the purpose and scope of the review. Include a methodology section describing how ideas, themes, and findings are compared across studies. Add key insights by identifying patterns, similarities, and differences. Highlight important trends, challenges, and meaningful research gaps. Finish by suggesting one realistic and testable hypothesis that logically follows from the discussion. Maintain a formal but clear writing style, prioritizing explanation and reasoning over definitions or lists.</p>
<p>The prompt was submitted to ChatGPT, Copilot, and Grok 3.</p>
</section>
<section id="model-response-analysis" class="level2">
<h2 class="anchored" data-anchor-id="model-response-analysis"><strong>Model Response Analysis</strong></h2>
<p>Each model response was evaluated using the following criteria:</p>
<p><strong>Structure</strong><br>
Did it include a methodology section and follow a systematic review format?</p>
<p><strong>Synthesis</strong><br>
Were key findings from data mining and machine learning applications well-summarized?</p>
<p><strong>Trends and Gaps</strong><br>
Did it identify meaningful trends and research gaps?</p>
<p><strong>Hypothesis Quality</strong><br>
Was the proposed hypothesis testable and relevant?</p>
<p><strong>References</strong><br>
Are the citations accurate (check using Google Scholar or Semantic Scholar)</p>
</section>
<section id="analyze-model-responses" class="level2">
<h2 class="anchored" data-anchor-id="analyze-model-responses"><strong>Analyze Model Responses</strong></h2>
<p><strong>Structure</strong></p>
<p>Regarding the structure, ChatGPT did a great job because it included a specific section explaining its methodology and followed a professional format. Copilot was also very organized and used clear headings that made the report easy to navigate. Grok 3 included a methodology paragraph as well, but the overall response felt more like one long essay rather than a structured review with clear sections.</p>
<p><strong>Synthesis</strong></p>
<p>When it comes to summarizing data mining and machine learning, ChatGPT was the only model that successfully stayed on topic. It explained how researchers are trying to balance making models accurate while also making them easy for humans to understand. Copilot completely missed the mark here because it wrote about technology in classrooms instead of data mining. Grok 3 focused almost entirely on how AI affects jobs and the economy, which was interesting but didn’t cover enough of the technical machine learning details.</p>
<p><strong>Trends and Gaps</strong></p>
<p>All three models tried to identify trends, but ChatGPT was the most relevant to the prompt by pointing out that researchers are moving away from simple predictions and looking for deeper causes. Copilot identified gaps in how technology affects different students, which was good but for the wrong subject. Grok 3 identified a very modern trend regarding “agentic AI” and noted that we still don’t have enough long-term data on how these systems behave.</p>
<p><strong>Hypothesis Quality</strong></p>
<p>The hypotheses provided were a bit of a mixed bag. ChatGPT created a strong, testable guess about whether adaptive models work better than static ones over a long period of time. Copilot also wrote a clear hypothesis about student learning, but it wasn’t relevant to the actual assignment topic of data mining. Grok 3 failed this part entirely because the response cut off at the end, so it never actually provided a hypothesis to test.</p>
<p><strong>References</strong></p>
<p>For the references and citations, all of the models struggled. None of them provided a list of specific papers, authors, or links that could be double-checked on Google Scholar or Semantic Scholar. They all spoke about “the literature” in a general way without giving credit to specific researchers, which makes it hard to verify if the information is coming from a real study.</p>
<p><strong>Strengths and Weaknesses</strong></p>
<p>In summary, ChatGPT’s main strength was following the instructions perfectly and staying on the right topic, but its weakness was the lack of real citations. Copilot’s strength was its very clean and easy-to-read structure, but its major weakness was hallucinating the wrong topic for the review. Grok 3’s strength was providing very deep and unique thoughts about current AI trends, but its biggest weakness was being incomplete and cutting off before finishing the task.</p>
</section>
<section id="refined-prompts" class="level2">
<h2 class="anchored" data-anchor-id="refined-prompts"><strong>Refined Prompts</strong></h2>
<p>After reviewing weaknesses, I revised the prompts.</p>
<p><strong>Refined Prompt for ChatGPT</strong></p>
<p>The biggest problem with ChatGPT’s first answer was that it did not name any real scientists or papers. It spoke in a very general way, which makes it hard to prove the information is true. This new prompt tells ChatGPT that it must include specific names and dates for its sources. It also asks for a bibliography at the end so we can check the work using Google Scholar or Semantic Scholar to make sure the citations are accurate.</p>
<p><strong>New Prompt for ChatGPT:</strong></p>
<p>Write a 1,500-word literature review about data mining and machine learning. You must include real in-text citations from academic studies, such as (Author, Year), to support your points. Include a methodology section that explains how you compared different studies. At the very end, provide a full list of references and one realistic, testable hypothesis that researchers could use for a new study.</p>
<p><strong>Refined Prompt for Microsoft Copilot</strong></p>
<p>Microsoft Copilot failed the first time because it wrote about the wrong topic, focusing on education instead of computer science. To fix this, the new prompt uses very strict instructions to stay on the subject of data mining and machine learning. Since Copilot is good at making things look neat, the prompt asks for a clear structure with specific sections for trends and gaps. This will help the model stay focused on the technical requirements of the assignment.</p>
<p><strong>New Prompt for Copilot:</strong></p>
<p>Write an analytical literature review of exactly 1,500 words about the technical applications of Data Mining and Machine Learning. Do not write about “human learning” or “education”; you must focus only on computer science topics like algorithm performance and data patterns. Organize the review with clear sections for methodology, key findings, and research gaps. End the discussion with a formal, testable hypothesis.</p>
<p><strong>Refined Prompt for Grok 3</strong></p>
<p>Grok 3’s first response was smart, but it was too short and it cut off before it could finish the job. It also focused too much on jobs and money instead of the actual technology. The new prompt tells Grok 3 to act like a data scientist and write a much longer review. It also tells the model to balance its time better so that it does not stop talking before it gets to the hypothesis at the very end.</p>
<p><strong>New Prompt for Grok 3:</strong></p>
<p>Imagine you are a data scientist writing a 2,000-word systematic literature review on data mining and machine learning in fields like healthcare and finance. You must provide a clear methodology and focus on the technical side of how models work, such as their accuracy and how they handle complex data. Ensure you manage the length of your response so it is complete. You must finish with a bold and testable hypothesis and a final conclusion.</p>
</section>
<section id="final-prompt" class="level2">
<h2 class="anchored" data-anchor-id="final-prompt"><strong>Final Prompt</strong></h2>
<p>After testing the new prompts, the results were much better because each AI finally followed the specific rules it missed the first time. ChatGPT became more trustworthy by adding real names and dates of scientists to support its ideas, while Copilot finally stopped talking about the wrong topic and stayed focused only on computer science. Grok 3 also did a better job by finishing its entire report and providing a smart “science guess” or hypothesis at the end instead of cutting off early. This shows that when you give an AI very clear instructions and fix its past mistakes, it can write a much more professional and complete paper for your project.</p>
<p>After collecting revised outputs, I used this synthesis prompt:</p>
<p>I am giving you three different drafts for a literature review on Data Mining and Machine Learning. Please combine them into one final 2,000-word systematic review. Use the real-world citations and the methodology from the first draft, the clear headings and organization from the second draft, and the modern technical insights from the third draft. Make sure the final document flows smoothly, maintains a formal tone, and ends with the most realistic and testable hypothesis. [I insert the three model outputs here.]</p>
</section>
<section id="reflection" class="level2">
<h2 class="anchored" data-anchor-id="reflection"><strong>Reflection</strong></h2>
<p><strong>How did the models respond differently?<br>
</strong>Each model handled the systematic review in a different way. ChatGPT focused on the technical history and professional structure of data mining, making sure to connect old methods with new ones. Microsoft Copilot focused more on the layout and organization of the report, though it struggled to stay on the correct topic at the beginning. Grok 3 focused on the newest trends and how AI affects the real world right now, but it had a hard time finishing long responses and often stopped before the end.</p>
<p><strong>Which refinements worked best?</strong><br>
The prompt refinements that worked best were the ones that added very specific requirements. For ChatGPT, telling it to include real-world citations with authors and dates made the review much more accurate. For Copilot, the most helpful change was using bold instructions to stay strictly on the topic of computer science so it wouldn’t talk about other subjects. For Grok 3, the best fix was asking it to be more concise and watch its length, which helped it complete the final sections and the hypothesis.</p>
<p><strong>What did this exercise demonstrate?</strong><br>
I learned that using AI for academic reviews requires a lot of back-and-forth work to get a good result. You cannot just use the first answer the AI gives you; you have to check for missing parts and fix the instructions to get better details. I also learned that it is best to use multiple models because one might be better at organizing while another is better at finding modern trends. The most important lesson is that a human must guide the AI and verify all the facts to make sure the final paper is correct and complete.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>